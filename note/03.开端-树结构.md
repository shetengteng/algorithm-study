数据结构和算法

![数据结构与算法](resource\数据结构与算法.jpg)

## 树 Tree

> 非线性结构

![8.树1](resource\8.树1.jpg)

每个元素：节点

相邻节点之间的关系：父子关系

![8.树2](resource\8.树2.jpg)

A是B的父节点，B是A的子节点，BCD是兄弟节点

E是根节点（没有父节点），GHIJKL是叶子节点（没有子节点）

节点的高度 Height：**节点到叶子节点**的最长路径（边数）

节点的深度 Depth：**根节点到这个节点**所经历的边数

节点的层数 Level：节点的深度+1

树的高度：根节点的高度

![8.树4](resource\8.树4.jpg)

### 二叉树 Binary Tree

每个节点最多有2个叉，**左子节点**，**右子节点**
![8.树5](resource\8.树5.jpg)

树2是满二叉树

树3是完全二叉树
![8.树6](resource\8.树6.jpg)

完全二叉树，叶子节点至少都是左叶子节点，父节点是满二叉树

> 为什么完全二叉树要如此定义？

> 是因为存储一个二叉树的方式而来，存储方式：基于指针或者二叉链式存储法；基于数组的顺序存储法。

#### 链式存储
![8.树7](resource\8.树7.jpg)

每个节点有left和right 2个引用存储点，通过根节点可以通过左右，访问所有的节点。该实现方式比较通用，大部分二叉树都是如此实现。

#### 顺序存储
![8.树8](resource\8.树8.jpg)

将根节点存储在下标i=1的位置，左子节点存在`2*i=2`的位置，右子节点存在`2*i+1=3`的位置，B节点存储在2的位置，那么B的左子节点存储在`2*2=4`的位置，B的右子节点存储在`2*2+1=5`的位置。

通过节点的存储下标x，可以得到该节点的左子节点和右子节点，为了便于计算，一般下标为0的位置不存储元素。

不足：使用顺序存储的二叉树，会对数组空间有浪费，因为是通过下标计算而得的二叉树。
![8.树9](resource\8.树9.jpg)

#### 二叉树遍历

对于遍历的顺序的不同，分为不同的遍历类型

本质上是一个递归调用过程

##### 前序遍历

对于树的任意节点而言，先打印本节点->左子**树**->右子**树**

##### 中序遍历

对于树的任意节点，先打印**左子树**->本节点->右子树

##### 后序遍历

对于树的任意节点，先打印**左子树**->**右子树**->本节点
![8.树10](resource\8.树10.jpg)

公式推导

```java
// 前序遍历的递推公式：
preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)
// 中序遍历的递推公式：
inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)
// 后序遍历的递推公式：
postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r

void preOrder(Node* root) {
  if (root == null) return;
  print root // 此处为伪代码，表示打印 root 节点
  preOrder(root->left);
  preOrder(root->right);
}

void inOrder(Node* root) {
  if (root == null) return;
  inOrder(root->left);
  print root // 此处为伪代码，表示打印 root 节点
  inOrder(root->right);
}

void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  print root // 此处为伪代码，表示打印 root 节点
}
```

##### 时间复杂度分析

由于每个节点访问2次，所以遍历操作的时间复杂度和节点个数n成正比，那么时间复杂度是O(n)



### 二叉查找树 Binary Search Tree

二叉搜索树，支持快速查找，插入，删除数据

要求：树中任意一个节点，左边子树节点值小于本节点值，右边子树节点值大于本节点值

#### 查找操作
![8.树11](resource\8.树11.jpg)

```java
public class BinarySearchTree {
  private Node tree;
    
  public Node find(int data) {
    Node p = tree;
    while (p != null) {
      if (data < p.data) p = p.left;
      else if (data > p.data) p = p.right;
      else return p;
    }
    return null;
  }

  public static class Node {
    private int data;
    private Node left;
    private Node right;

    public Node(int data) {
      this.data = data;
    }
  }
}
```

#### 插入操作

插入操作前，先找到要插入的节点的位置，新插入的数据一般都在叶子节点上，从根节点开始，依次比较要插入的数据和节点的大小关系。
![8.树12](resource\8.树12.jpg)

```java
public void insert(int data){
    if(tree == null){
        tree = new Node(data);
        return;
    }
    Node p = tree;
    while(p != null){
        if(p.data == data){
            return;
        }
        if(data < p.data){
            if(p.left == null){
                p.left = new Node(data);
                return;
            }
            p = p.left;
        }
        if(data > p.data){
            if(p.right == null){
                p.right = new Node(data);
                return;
            }
            p = p.right;
        }
    }
}
```

#### 删除操作

- 如果要删除的没有子节点，在该节点的父节点中对应的位置设置为null
- 如果删除的节点只有一个子节点（左子节点或者右子节点），该子节点的父节点对应的位置用孙子节点进行替换
- 如果要删除的节点有2个子节点（左子节点和右子节点都存在），找到该节点的右子树的最小节点，作为替换该节点在父节点的位置，为什么是右子树的最小节点？
  - 首先右子树的最小节点是叶子节点，没有子节点，那么替换操作不会有其他节点替换
  - 右子树的最小节点也比左子树的所有节点大，最合适

![8.树13](resource\8.树13.jpg)

```java
public void delete(int data){
    // 先指向根节点
    Node current = tree;
    // 查询得到data的父节点
    Node parent = null;
    while(current != null){
        if(data == current.data){
            break;
        }
        parent = current;
        current = data > current.data ? current.right : current.left;
    }
    // 没有找到
    if(current == null){
        return;
    }

    // 要删除的节点有左右子节点
    if(current.right != null && current.left != null){
        Node minParent = current;
        Node min = minParent.right;
        // 找到右子树中最小的节点
        // 在右子树的左子树进行遍历，得到最小点，左边比右边小
        // 或者可以找到左子树最大的点也是可以的
        while(min.left != null){
            minParent = min;
            min = minParent.left;
        }
        // 说明min.left 为null，那么在右子树的最小节点就找到了
        // 只需要将data进行替换，left和right不需要替换
        current.data = min.data;
        // 将min给current，minParent给Parent
        // 接下来的操作是对min点的删除
        // 此时的min点就是叶子节点
        current = min;
        parent = minParent;
    }
    // 删除节点是叶子节点，或者只有一个子节点
    Node child = null;
    if(current.left != null){
        child = current.left;
    }
    if(current.right != null){
        child = current.right;
    }

    // 删除的是根节点
    if(parent == null){
        tree = child;
    }else if(parent.left == current){
        // 判断current在parent的具体位置，进行替换为child
        parent.left = child;
    }else {
        parent.right = child;
    }
}
```

还有一种删除操作，是将删除的节点标记为已删除，时间复杂度最低，实现简单，但是内存消耗高

#### 其他操作

查找前驱节点

查找后继节点

查找最大点

查找最小点

中序遍历二叉查找树，可以输出有序的数据队列，时间复杂度是O(n)，二叉排序树

#### 支持重复数据的二叉查找树

二叉树节点存储对象，利用某个字段作为key进行存储，其他属性作为卫星数据

如何存储相同key值的数据？

**方式1**：将相同节点处设计为链表或者动态数组，支持扩容，把相同的数据的对象存储在节点链表上
方式2：每个节点也存储一个数据，不过相同的key的节点，放在右子树，具体操作如下
![](resource\8.树14.jpg)
![](resource\8.树15.jpg)
![](resource\8.树16.jpg)

#### 时间复杂度分析

最差情况，链表

最好情况，满二叉树

![](resource\8.树17.jpg)

时间负载度与树的高度成正比，O(height)，那么二叉树的时间复杂度就是计算一个完全二叉树的的高度

高度是L-1（最大层-1），在有n个节点的完全二叉树，第一层有1个节点，第二层有2个节点，第三层有3个节点，那么第k层有2^(k-1)个节点，那么L是最大层数，n的范围如下

```java
n >= 1+2+4+8+...+2^(L-2)+1
n <= 1+2+4+8+...+2^(L-2)+2^(L-1)
计算出L的范围[log2(n+1),log2(n)+1]
```

那么时间复杂度就是O(logn)，极度不平衡的二叉树的时间复杂度是O(n)，在平衡二叉树中，时间复杂度就是O(logn)

#### 与散列表的比较

散列表的时间复杂度是O(1)，而二叉树是O(logn)，那么有些场景使用二叉树，而不是用散列表：

- 顺序性输出
  - 散列表是无序的，如果要输出有序数据，要先进行排序
  - 对于二叉树只需要进行中序遍历，就可以得到有序数据，复杂度是O(n)
- 扩容耗时
  - 散列表在出现散列冲突的时候，性能不稳定
  - 平衡二叉树性能稳定在O(logn)
- 性能
  - 有hash函数的计算耗时，以及散列冲突的处理耗时，因此查询的时间复杂度O(1)不一定比O(logn)小
- 结构实现
  - 散列表的构造比二叉树复杂，需要维护的东西比较多，散列函数的设计，散列冲突的处理，扩容与缩容的设计
  - 二叉树只要考虑到平衡性即可，现有很多技术可以实现
- 其他
  - 散列表的装载因子不能太大，否则会有过多的散列冲突，那么就会导致内存的浪费



### 平衡二叉查找树

**平衡二叉树**中**任意一个节点**的左右子树的高度相差不能大于1，那么完全二叉树，满二叉树都是平衡二叉树，非完全二叉树也可能是平衡二叉树

![](resource\8.树18.jpg)

平衡二叉树有红黑树，伸展树，树堆，AVL树

出现的意义，让左右子树尽量平衡，从而在二叉树频繁插入和删除等动态更新树的情况下，减少时间复杂度退化

左右子树尽量对称平衡，那么树的高度会保持一个很矮的状态，从而达到时间复杂度维持在O(logn)，因此，只要树的高度不比O(logn)大很多，那么就可以是一个合格的平衡二叉树。



#### 红黑树 Red-Black Tree *

> R-B Tree 不严格的平衡二叉查找树
>
> 根节点是黑色的
> 每个叶子节点都是空的黑色节点（NIL），叶子节点不存储数据，为了便于实现
> 任何相邻的节点不能同时为红色，红色与黑色是分隔开的
> 每个节点到其叶子节点的所有路径，包含的黑色节点的数目一致

这里示例的节点去除了空的黑色节点
![](resource\8.树19.jpg)

红黑树是近似平衡的，性能不会退化的太严重

##### 时间复杂度

树的时间复杂度与树的高度有关，那么计算红黑树的高度即可计算出时间复杂度，由于红黑树的红色节点和黑色节点是交替的，那么先将红色节点去除，至少是一个完全二叉树，那么完全二叉树的高度是log<sub>2</sub>n（全部黑色的节点的高度是小于log<sub>2</sub>n的），再将红色点添加回来，层数*2，那么是2log<sub>2</sub>n，时间复杂度等价于O(logn)

![](resource\8.树20.jpg)

##### 与其他树的比较

其他的平衡二叉树：Treap，Splay Tree 在大多情况下，操作的效率比较高，无法避免极端情况下的时间复杂度的退化，如果对单次操作比较敏感的情况下考虑，并不适用

AVL是高度平衡的二叉树，查找效率高，但是每次插入和删除都要调整，对于频繁插入和删除操作数据集合AVL代价就比较高了

红黑树做到了近似的平衡，在维护平衡性上比AVL性能要高，而且插入删除和查询操作都比较稳定，因此在工业级别使用红黑树。

##### 实现思想

类似于魔方复原，针对不同的节点排布，进行相应的调整，设计要求：

- **根节点**是黑色的
- 每个叶子节点都是黑色的，并且为空NIL，叶子节点不存储数据
- 任何相邻的节点不能是红色的，红色节点被黑色节点隔开
- 每个节点到其他可以到达该节点的叶子节点，包含相同数据的黑色节点

在插入和删除节点后，会将后2条破坏掉，因此要恢复后2条。

操作

- 左旋 rotate left：围绕某个节点左旋

- 右旋 rotate right：围绕某个节点右旋

![](resource\8.树21.jpg)

###### 插入操作的平衡调整

- 插入的节点必须是红色

- 二叉树插入的节点都是放在叶子节点上

- 如果插入的父节点是黑色的，不用处理

- 如果插入的节点是根节点，改变节点为黑色

- 其他情况下要进行**左右旋转**和**改变颜色**

定义：正在处理的节点--**关注节点**，随着不停的迭代处理，而不断变化，初始的关注节点就是插入节点

插入节点后有3中情况：需要不断调整，满足红黑树的要求



### 递归树

使用递归树求解时间复杂度，如斐波拉契数列的计算的复杂度

![9.递归树1](resource\9.递归树1.jpg)

归并排序使用递归树进行计算时间复杂度

![9.递归树2](resource\9.递归树2.jpg)

每次分解操作的代价很低，时间的损耗可以看做1，归并算法中比较耗时的是归并操作，每层的归并的数组长度之和都相同，都是n，如果树的高度是h，那么可以得到时间复杂度O(n*h)，而归并算法的递归树是一个**满二叉树**，h=logn，那么时间复杂度就是O(nlogn)，

#### 分析快速排序的时间复杂度 * 

快速排序在分区均分的情况下，时间复杂度是比较容易计算的

T(n) = 2T($\frac{n}{2}$)+n，可以推导出O(nlogn)，如果不是一份为二的话，那么就复杂了

考虑1:9的切分情况T(n) = T($\frac{n}{10}$)+T($\frac{9n}{10}​$)+n

![9.递归树3](resource\9.递归树3.jpg)

快速排序中，每次分区都要遍历待分区间的数组的所有元素，那么由于每一层计算的耗时复杂度都是n，然后计算出树的高度h，就可以得到快速排序算法的时间复杂度O(h*n)，如果是满二叉树，那么h就是logn，故快速排序算法的时间复杂度是O(nlogn)

![1551792508977](E:\algorithm-data-structure\note\resource\9.递归树4.jpg)

