数据结构和算法

![数据结构与算法](resource\数据结构与算法.jpg)

## 树 Tree

> 非线性结构

![8.树1](resource\8.树1.jpg)

每个元素：节点

相邻节点之间的关系：父子关系

![8.树2](resource\8.树2.jpg)

A是B的父节点，B是A的子节点，BCD是兄弟节点

E是根节点（没有父节点），GHIJKL是叶子节点（没有子节点）

节点的高度 Height：**节点到叶子节点**的最长路径（边数）

节点的深度 Depth：**根节点到这个节点**所经历的边数

节点的层数 Level：节点的深度+1

树的高度：根节点的高度

![8.树4](resource\8.树4.jpg)

### 二叉树 Binary Tree

每个节点最多有2个叉，**左子节点**，**右子节点**
![8.树5](resource\8.树5.jpg)

树2是满二叉树

树3是完全二叉树
![8.树6](resource\8.树6.jpg)

完全二叉树，叶子节点至少都是左叶子节点，父节点是满二叉树

> 为什么完全二叉树要如此定义？

> 是因为存储一个二叉树的方式而来，存储方式：基于指针或者二叉链式存储法；基于数组的顺序存储法。

#### 链式存储
![8.树7](resource\8.树7.jpg)

每个节点有left和right 2个引用存储点，通过根节点可以通过左右，访问所有的节点。该实现方式比较通用，大部分二叉树都是如此实现。

#### 顺序存储
![8.树8](resource\8.树8.jpg)

将根节点存储在下标i=1的位置，左子节点存在`2*i=2`的位置，右子节点存在`2*i+1=3`的位置，B节点存储在2的位置，那么B的左子节点存储在`2*2=4`的位置，B的右子节点存储在`2*2+1=5`的位置。

通过节点的存储下标x，可以得到该节点的左子节点和右子节点，为了便于计算，一般下标为0的位置不存储元素。

不足：使用顺序存储的二叉树，会对数组空间有浪费，因为是通过下标计算而得的二叉树。
![8.树9](resource\8.树9.jpg)

#### 二叉树遍历

对于遍历的顺序的不同，分为不同的遍历类型

本质上是一个递归调用过程

##### 前序遍历

对于树的任意节点而言，先打印本节点->左子**树**->右子**树**

##### 中序遍历

对于树的任意节点，先打印**左子树**->本节点->右子树

##### 后序遍历

对于树的任意节点，先打印**左子树**->**右子树**->本节点
![8.树10](resource\8.树10.jpg)

公式推导

```java
// 前序遍历的递推公式：
preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)
// 中序遍历的递推公式：
inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)
// 后序遍历的递推公式：
postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r

void preOrder(Node* root) {
  if (root == null) return;
  print root // 此处为伪代码，表示打印 root 节点
  preOrder(root->left);
  preOrder(root->right);
}

void inOrder(Node* root) {
  if (root == null) return;
  inOrder(root->left);
  print root // 此处为伪代码，表示打印 root 节点
  inOrder(root->right);
}

void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  print root // 此处为伪代码，表示打印 root 节点
}
```

##### 时间复杂度分析

由于每个节点访问2次，所以遍历操作的时间复杂度和节点个数n成正比，那么时间复杂度是O(n)



### 二叉查找树 Binary Search Tree

二叉搜索树，支持快速查找，插入，删除数据

要求：树中任意一个节点，左边子树节点值小于本节点值，右边子树节点值大于本节点值

#### 查找操作
![8.树11](resource\8.树11.jpg)

```java
public class BinarySearchTree {
  private Node tree;
    
  public Node find(int data) {
    Node p = tree;
    while (p != null) {
      if (data < p.data) p = p.left;
      else if (data > p.data) p = p.right;
      else return p;
    }
    return null;
  }

  public static class Node {
    private int data;
    private Node left;
    private Node right;

    public Node(int data) {
      this.data = data;
    }
  }
}
```

#### 插入操作

插入操作前，先找到要插入的节点的位置，新插入的数据一般都在叶子节点上，从根节点开始，依次比较要插入的数据和节点的大小关系。
![8.树12](resource\8.树12.jpg)

```java
public void insert(int data){
    if(tree == null){
        tree = new Node(data);
        return;
    }
    Node p = tree;
    while(p != null){
        if(p.data == data){
            return;
        }
        if(data < p.data){
            if(p.left == null){
                p.left = new Node(data);
                return;
            }
            p = p.left;
        }
        if(data > p.data){
            if(p.right == null){
                p.right = new Node(data);
                return;
            }
            p = p.right;
        }
    }
}
```

#### 删除操作

- 如果要删除的没有子节点，在该节点的父节点中对应的位置设置为null
- 如果删除的节点只有一个子节点（左子节点或者右子节点），该子节点的父节点对应的位置用孙子节点进行替换
- 如果要删除的节点有2个子节点（左子节点和右子节点都存在），找到该节点的右子树的最小节点，作为替换该节点在父节点的位置，为什么是右子树的最小节点？
  - 首先右子树的最小节点是叶子节点，没有子节点，那么替换操作不会有其他节点替换
  - 右子树的最小节点也比左子树的所有节点大，最合适

![8.树13](resource\8.树13.jpg)

```java
public void delete(int data){
    // 先指向根节点
    Node p = tree;
    // 查询得到data的父节点
    Node pp = null;
    while(p != null){
        if(data == p.data){
            break;
        }
        pp = p;
        p = data > p.data ? p.right : p.left;
    }
    // 没有找到
    if(p == null){
        return;
    }
    // 要删除的节点有左右子节点
    if(p.right != null && p.left != null){
        Node minP = p;
        Node min = minP.right;
        // 找到右子树中最小的节点
        // 在右子树的左子树进行遍历，得到最小点，左边比右边小
        while(min.left != null){
            minP = min;
            min = minP.left;
        }
        // 说明min.left 为null，那么在右子树的最小节点就找到了
        p.data = min.data;
        p = min;
        pp = minP;
    }

    // 删除节点是叶子节点，或者只有一个子节点
    Node child = null;
    if(p.left != null){
        child = p.left;
    }
    if(p.right != null){
        child = p.right;
    }

    // 删除的是根节点
    if(pp == null){
        tree = child;
    }else if(pp.left == p){
        pp.left = child;
    }else {
        pp.right = child;
    }
}
```

还有一种删除操作，是将删除的节点标记为已删除，时间复杂度最低，实现简单，但是内存消耗高

#### 其他操作

查找前驱节点

查找后继节点

查找最大点

查找最小点

中序遍历二叉查找树，可以输出有序的数据队列，时间复杂度是O(n)，二叉排序树

#### 支持重复数据的二叉查找树

二叉树节点存储对象，利用某个字段作为key进行存储，其他属性作为卫星数据

如何存储相同key值的数据？

**方式1**：将相同节点处设计为链表或者动态数组，支持扩容，把相同的数据的对象存储在节点链表上
方式2：每个节点也存储一个数据，不过相同的key的节点，放在右子树，具体操作如下
![](resource\8.树14.jpg)
![](resource\8.树15.jpg)
![](resource\8.树16.jpg)

#### 时间复杂度分析

最差情况，链表

最好情况，满二叉树

![](resource\8.树17.jpg)

时间负载度与树的高度成正比，O(height)，那么二叉树的时间复杂度就是计算一个完全二叉树的的高度

高度是L-1（最大层-1），在有n个节点的完全二叉树，第一层有1个节点，第二层有2个节点，第三层有3个节点，那么第k层有2^(k-1)个节点，那么L是最大层数，n的范围如下

```java
n >= 1+2+4+8+...+2^(L-2)+1
n <= 1+2+4+8+...+2^(L-2)+2^(L-1)
计算出L的范围[log2(n+1),log2(n)+1]
```

那么时间复杂度就是O(logn)，极度不平衡的二叉树的时间复杂度是O(n)，在平衡二叉树中，时间复杂度就是O(logn)

#### 与散列表的比较

散列表的时间复杂度是O(1)，而二叉树是O(logn)，那么有些场景使用二叉树，而不是用散列表：

- 顺序性输出
  - 散列表是无序的，如果要输出有序数据，要先进行排序
  - 对于二叉树只需要进行中序遍历，就可以得到有序数据，复杂度是O(n)
- 扩容耗时
  - 散列表在出现散列冲突的时候，性能不稳定
  - 平衡二叉树性能稳定在O(logn)
- 性能
  - 有hash函数的计算耗时，以及散列冲突的处理耗时，因此查询的时间复杂度O(1)不一定比O(logn)小
- 结构实现
  - 散列表的构造比二叉树复杂，需要维护的东西比较多，散列函数的设计，散列冲突的处理，扩容与缩容的设计
  - 二叉树只要考虑到平衡性即可，现有很多技术可以实现
- 其他
  - 散列表的装载因子不能太大，否则会有过多的散列冲突，那么就会导致内存的浪费



### 平衡二叉查找树

**平衡二叉树**中**任意一个节点**的左右子树的高度相差不能大于1，那么完全二叉树，满二叉树都是平衡二叉树，非完全二叉树也可能是平衡二叉树

![](resource\8.树18.jpg)

平衡二叉树有红黑树，伸展树，树堆，AVL树

出现的意义，让左右子树尽量平衡，从而在二叉树频繁插入和删除等动态更新树的情况下，减少时间复杂度退化

左右子树尽量对称平衡，那么树的高度会保持一个很矮的状态，从而达到时间复杂度维持在O(logn)，因此，只要树的高度不比O(logn)大很多，那么就可以是一个合格的平衡二叉树。

#### 红黑树 Red-Black Tree 

> R-B Tree 不严格的平衡二叉查找树
>
> 根节点是黑色的
> 每个叶子节点都是空的黑色节点（NIL），叶子节点不存储数据，为了便于实现
> 任何相邻的节点不能同时为红色，红色与黑色是分隔开的
> 每个节点到其叶子节点的所有路径，包含的黑色节点的数目一致

这里示例的节点去除了空的黑色节点
![](resource\8.树19.jpg)




### 递归树



